name: "ðŸ” Analisar Live com Gemini"

on:
  workflow_dispatch:
    inputs:
      senha:
        description: "ðŸ”’ Digite a senha para executar"
        required: true
        type: string

permissions:
  contents: write

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    steps:
      - name: "ðŸ”’ Verificar senha"
        env:
          SENHA_CORRETA: ${{ secrets.SENHA }}
          SENHA_INPUT: ${{ github.event.inputs.senha }}
        run: |
          if [ "$SENHA_INPUT" != "$SENHA_CORRETA" ]; then
            echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
            echo "â•‘   ðŸš« SENHA INCORRETA - NEGADO    â•‘"
            echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            exit 1
          fi
          echo "âœ… Senha correta"

      - name: Checkout apiss repo
        uses: actions/checkout@v4
        with:
          repository: Alisson990jd/apiss
          token: ${{ secrets.GH_PAT }}
          ref: main
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: "ðŸ” Analisar com Gemini"
        shell: bash
        run: |
          set +e

          ##############################################################
          # CONFIGURAÃ‡Ã•ES
          ##############################################################
          ANALYSIS_FILE="analisar/analise_completa.txt"
          KEYS_FILE="gemini_keys_only.txt"
          KEY_MAP_FILE="key_project_map.json"
          USAGE_FILE="key_usage.json"
          OUTPUT_DIR="analysis_output"
          SEGMENTS_PER_CHUNK=60
          COOLDOWN_HOURS=48
          MODEL="gemini-2.5-flash"

          mkdir -p "$OUTPUT_DIR" tmp_chunks tmp_venvs

          ##############################################################
          # VERIFICAR ARQUIVOS
          ##############################################################
          if [ ! -f "$ANALYSIS_FILE" ]; then
            echo "âŒ Arquivo de anÃ¡lise nÃ£o encontrado: $ANALYSIS_FILE"
            ls -la analisar/ 2>/dev/null || echo "Pasta analisar/ nÃ£o existe"
            exit 1
          fi

          if [ ! -f "$KEYS_FILE" ]; then
            echo "âŒ Arquivo de keys nÃ£o encontrado: $KEYS_FILE"
            exit 1
          fi

          if [ ! -f "$KEY_MAP_FILE" ]; then
            echo '{}' > "$KEY_MAP_FILE"
          fi

          if [ ! -f "$USAGE_FILE" ]; then
            echo '{"used_keys":[],"expired_keys":[]}' > "$USAGE_FILE"
          fi

          echo "ðŸ“„ Arquivo de anÃ¡lise: $(wc -l < "$ANALYSIS_FILE") linhas"
          echo "ðŸ”‘ Keys disponÃ­veis: $(wc -l < "$KEYS_FILE")"
          echo "ðŸ“Ž Mapeamento key->projeto: $(python3 -c "import json; print(len(json.load(open('$KEY_MAP_FILE'))))" 2>/dev/null || echo 0) entries"

          ##############################################################
          # FUNÃ‡Ã•ES DE GERENCIAMENTO DE KEYS
          ##############################################################
          get_available_key() {
            local NOW_EPOCH
            NOW_EPOCH=$(date -u +%s)
            local COOLDOWN_SECS=$((COOLDOWN_HOURS * 3600))

            # Limpar entries expiradas do cooldown
            python3 - "$USAGE_FILE" "$NOW_EPOCH" "$COOLDOWN_SECS" <<'PYCLEAN'
          import json, sys

          usage_file = sys.argv[1]
          now_epoch = int(sys.argv[2])
          cooldown_secs = int(sys.argv[3])

          with open(usage_file, 'r') as f:
              data = json.load(f)

          data['used_keys'] = [e for e in data.get('used_keys', [])
                               if now_epoch - e.get('timestamp', 0) < cooldown_secs]
          data['expired_keys'] = [e for e in data.get('expired_keys', [])
                                  if now_epoch - e.get('timestamp', 0) < cooldown_secs]

          with open(usage_file, 'w') as f:
              json.dump(data, f, indent=2)
          PYCLEAN

            # Pegar keys bloqueadas
            local BLOCKED_KEYS
            BLOCKED_KEYS=$(python3 - "$USAGE_FILE" <<'PYBLOCK'
          import json, sys
          with open(sys.argv[1], 'r') as f:
              data = json.load(f)
          keys = set()
          for e in data.get('used_keys', []):
              k = e.get('key', '')
              if k:
                  keys.add(k)
          for e in data.get('expired_keys', []):
              k = e.get('key', '')
              if k:
                  keys.add(k)
          for k in keys:
              print(k)
          PYBLOCK
            )

            # Encontrar key disponÃ­vel
            while IFS= read -r KEY; do
              [ -z "$KEY" ] && continue
              KEY=$(echo "$KEY" | tr -d '[:space:]')
              if ! echo "$BLOCKED_KEYS" | grep -qF "$KEY"; then
                echo "$KEY"
                return 0
              fi
            done < "$KEYS_FILE"

            echo ""
            return 1
          }

          get_project_for_key() {
            local KEY="$1"
            python3 - "$KEY_MAP_FILE" "$KEY" <<'PYPROJ'
          import json, sys
          try:
              with open(sys.argv[1], 'r') as f:
                  data = json.load(f)
              key = sys.argv[2]
              entry = data.get(key, {})
              project = entry.get('project', '') if isinstance(entry, dict) else ''
              print(project)
          except:
              print('')
          PYPROJ
          }

          mark_key_used() {
            local KEY="$1"
            local CHUNK_ID="$2"
            local PROJECT="$3"
            local NOW_EPOCH
            NOW_EPOCH=$(date -u +%s)

            python3 - "$USAGE_FILE" "$KEY" "$CHUNK_ID" "$NOW_EPOCH" "$PROJECT" <<'PYMARK'
          import json, sys, datetime

          usage_file = sys.argv[1]
          key = sys.argv[2]
          chunk_id = sys.argv[3]
          timestamp = int(sys.argv[4])
          project = sys.argv[5]

          with open(usage_file, 'r') as f:
              data = json.load(f)

          data['used_keys'].append({
              "key": key,
              "project": project,
              "chunk_id": chunk_id,
              "timestamp": timestamp,
              "date": datetime.datetime.utcfromtimestamp(timestamp).isoformat() + "Z"
          })

          with open(usage_file, 'w') as f:
              json.dump(data, f, indent=2)
          PYMARK
          }

          mark_key_expired() {
            local KEY="$1"
            local REASON="$2"
            local PROJECT="$3"
            local NOW_EPOCH
            NOW_EPOCH=$(date -u +%s)

            python3 - "$USAGE_FILE" "$KEY" "$REASON" "$NOW_EPOCH" "$PROJECT" <<'PYEXP'
          import json, sys, datetime

          usage_file = sys.argv[1]
          key = sys.argv[2]
          reason = sys.argv[3]
          timestamp = int(sys.argv[4])
          project = sys.argv[5]

          with open(usage_file, 'r') as f:
              data = json.load(f)

          data['used_keys'] = [e for e in data['used_keys'] if e.get('key') != key]

          data['expired_keys'].append({
              "key": key,
              "project": project,
              "reason": reason,
              "timestamp": timestamp,
              "date": datetime.datetime.utcfromtimestamp(timestamp).isoformat() + "Z"
          })

          with open(usage_file, 'w') as f:
              json.dump(data, f, indent=2)
          PYEXP
          }

          ##############################################################
          # DIVIDIR ARQUIVO EM CHUNKS DE 60 SEGMENTOS
          ##############################################################
          echo ""
          echo "ðŸ“¦ Dividindo arquivo em chunks de $SEGMENTS_PER_CHUNK segmentos..."

          python3 - "$ANALYSIS_FILE" "tmp_chunks" "$SEGMENTS_PER_CHUNK" <<'PYSPLIT'
          import sys, re, os

          analysis_file = sys.argv[1]
          output_dir = sys.argv[2]
          segments_per_chunk = int(sys.argv[3])

          with open(analysis_file, 'r', encoding='utf-8', errors='replace') as f:
              content = f.read()

          header_match = re.search(r'^(.*?)(?=={10,}\nMINUTO\s+\d+)', content, re.DOTALL)
          header = header_match.group(1).strip() if header_match else ""

          segment_pattern = re.compile(
              r'(={10,}\nMINUTO\s+(\d+)\s*\|[^\n]*\n={10,}\n.*?)(?=\n={10,}\nMINUTO\s+\d+|\n={10,}\nCONCLUIDO|\n={10,}\nANALISE|\Z)',
              re.DOTALL
          )

          segments = []
          seen_minutes = set()

          for match in segment_pattern.finditer(content):
              seg_text = match.group(1).strip()
              minute_num = int(match.group(2))
              if minute_num not in seen_minutes:
                  segments.append((minute_num, seg_text))
                  seen_minutes.add(minute_num)

          segments.sort(key=lambda x: x[0])
          print(f"Total de segmentos unicos encontrados: {len(segments)}")

          os.makedirs(output_dir, exist_ok=True)
          chunk_num = 0

          for i in range(0, len(segments), segments_per_chunk):
              chunk_segments = segments[i:i + segments_per_chunk]
              chunk_num += 1

              chunk_content = header + "\n\n" if header and chunk_num == 1 else ""
              chunk_content += f"# CHUNK {chunk_num} - Segmentos {chunk_segments[0][0]} a {chunk_segments[-1][0]}\n\n"

              for minute_num, seg_text in chunk_segments:
                  chunk_content += seg_text + "\n\n"

              chunk_file = os.path.join(output_dir, f"chunk_{chunk_num:04d}.txt")
              with open(chunk_file, 'w', encoding='utf-8') as f:
                  f.write(chunk_content)

              seg_range = f"{chunk_segments[0][0]}-{chunk_segments[-1][0]}"
              print(f"  Chunk {chunk_num}: {len(chunk_segments)} segmentos (min {seg_range})")

          print(f"\nTotal de chunks: {chunk_num}")
          PYSPLIT

          TOTAL_CHUNKS=$(ls tmp_chunks/chunk_*.txt 2>/dev/null | wc -l)
          echo ""
          echo "ðŸ“¦ Total de chunks: $TOTAL_CHUNKS"

          if [ "$TOTAL_CHUNKS" -eq 0 ]; then
            echo "âŒ Nenhum chunk gerado"
            exit 1
          fi

          ##############################################################
          # PROMPT TEMPLATE
          ##############################################################
          cat > tmp_prompt_template.txt <<'PROMPT_END'
          (LEIA COM ATENÃ‡ÃƒO) VocÃª receberÃ¡ um arquivo TXT anexado que descreve o que aconteceu em cada segmento de uma live da plataforma Twitch. Cada segmento foi gerado pelo meu pipeline em blocos de 1 minuto consecutivo (ou seja, segmento 0 = 00:00:00â€“00:00:59, segmento 1 = 00:01:00â€“00:01:59, e assim por diante). O texto pode incluir tempos internos relativos (ex.: "00:45" dentro do segmento).

          Esta anÃ¡lise Ã© de uma live da Twitch. Considere elementos tÃ­picos como raids, subs, bits, emotes, interaÃ§Ãµes com chat da Twitch e momentos de "hype".

          Sua tarefa: analisar o conteÃºdo do arquivo e retornar APENAS um objeto JSON com uma lista de clipes recomendados para publicar em YouTube (monetizÃ¡vel) e TikTok (monetizÃ¡vel). Nada alÃ©m do JSON â€“ sem introduÃ§Ã£o, sem explicaÃ§Ãµes, sem comentÃ¡rios.

          Regras e requisitos obrigatÃ³rios:

          SaÃ­da somente JSON (vÃ¡lido).

          Cada item em clips deve seguir EXATAMENTE esta estrutura e nesta ordem de chaves:

          clip_id (string): formato "clip_{start}_{end}" em segundos, ex: "clip_120_780".

          platform (string): "youtube" ou "tiktok" ou "both".

          title (string): tÃ­tulo curto pronto para usar.

          category (string): uma das ["gameplay","IRL","just_chatting","react"].

          start_time (string, hh:mm:ss) â€“ instante inicial absoluto desde o inÃ­cio da live.

          end_time (string, hh:mm:ss) â€“ instante final absoluto.

          duration_seconds (integer).

          segments_combined (array of integers): Ã­ndices dos segmentos originais combinados (p.ex. [2,3,4,5]).

          reason (string): 1-2 frases curtas (mÃ¡x 30 palavras) dizendo por que clipar.

          tags (array of strings): atÃ© 8 tags relevantes.

          monetizable (boolean): true ou false.

          safety_flags (array of strings): vazio [] se nenhum problema; caso contrÃ¡rio inclua flags como "copyright_music", "explicit_sex", "hate_speech", "privacy_issue", "medical_misinformation", etc.

          recommended_description (string): 1-3 frases curtas para usar na descriÃ§Ã£o (mÃ¡x 40 palavras).

          thumbnail_text (string): texto curto (3â€“6 palavras) chamativo para thumbnail.

          thumbnail_timestamp (string, hh:mm:ss): momento exato dentro do clipe para tirar a screenshot da thumbnail.

          Regras de duraÃ§Ã£o e combinaÃ§Ã£o (CRÃTICO: Segmentos sÃ£o curtos de 1 min):

          Para YouTube monetizÃ¡vel: cada clip deve ter â‰¥ 600 segundos (10 minutos).

          Como cada segmento tem apenas 1 minuto, vocÃª OBRIGATORIAMENTE deve combinar pelo menos 10 segmentos contÃ­guos.

          Prefira gerar clipes com 900â€“1800 segundos (15 a 30 minutos), combinando de 15 a 30 segmentos adjacentes.

          NÃ£o junte partes nÃ£o-contÃ­guas (os clipes precisam ser contÃ­nuos na linha do tempo).

          Para TikTok monetizÃ¡vel: cada clip deve ter â‰¥ 60 segundos.

          Como cada segmento jÃ¡ tem ~60s, verifique se o evento comeÃ§a e termina no mesmo segmento. Se o evento interessante cortar a virada do minuto, combine 2 ou mais segmentos para nÃ£o cortar o contexto.

          Se o mesmo trecho serve para ambas as plataformas sem violar os mÃ­nimos, use "both" e mantenha start_time/end_time do trecho combinado.

          DetecÃ§Ã£o de gameplay completa:

          AlÃ©m dos clipes normais, se o arquivo mostrar que o streamer jogou um jogo especÃ­fico de forma contÃ­nua por longos perÃ­odos, gere tambÃ©m clipes inteiros cobrindo toda a gameplay.

          Esses clipes de gameplay completa devem ser marcados com category:"gameplay" e podem ter vÃ¡rias horas (centenas de segmentos combinados).

          O tÃ­tulo e o thumbnail_text devem ser genÃ©ricos mas chamativos.

          GeraÃ§Ã£o de timestamps:

          Use horas absolutas desde o inÃ­cio da live em formato hh:mm:ss.

          Calcule duration_seconds exatamente (end - start).

          Se o texto trouxer tempos relativos internos (ex.: "aos 00:30 do segmento"), converta corretamente para o tempo absoluto usando o Ã­ndice do segmento: (segment_index * 60s) + offset_segundos.

          Formato JSON e validaÃ§Ã£o:

          Retorne apenas o JSON bem formado. Ex.: {"clips":[{...},{...}]}.

          Ordem das chaves em cada clip deve seguir exatamente a lista do item (2).

          EXEMPLO DE SAÃDA:
          {
          "clips":[
          {
          "clip_id":"clip_120_1680",
          "platform":"youtube",
          "title":"Melhores momentos da partida",
          "category":"gameplay",
          "start_time":"00:02:00",
          "end_time":"00:28:00",
          "duration_seconds":1560,
          "segments_combined":[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27],
          "reason":"sequÃªncia de jogadas com muita reaÃ§Ã£o do pÃºblico",
          "tags":["gameplay","highlights","reaction"],
          "monetizable":true,
          "safety_flags":[],
          "recommended_description":"Melhores momentos da partida em uma sequÃªncia Ã©pica com muita emoÃ§Ã£o!",
          "thumbnail_text":"Jogada insana!",
          "thumbnail_timestamp":"00:15:00"
          }
          ]
          }

          Agora analise o conteÃºdo abaixo e gere somente o JSON seguindo todas as regras acima.

          PROMPT_END

          ##############################################################
          # PROCESSAR CADA CHUNK
          ##############################################################
          echo ""
          echo "ðŸš€ Iniciando anÃ¡lise de $TOTAL_CHUNKS chunks..."
          echo ""

          CHUNK_NUM=0
          SUCCESS_COUNT=0
          TOTAL_CLIPS=0

          for CHUNK_FILE in $(ls tmp_chunks/chunk_*.txt | sort -V); do
            CHUNK_NUM=$((CHUNK_NUM + 1))
            CHUNK_NAME=$(basename "$CHUNK_FILE" .txt)

            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo "ðŸ“¦ Chunk $CHUNK_NUM/$TOTAL_CHUNKS: $CHUNK_NAME"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

            CHUNK_LINES=$(wc -l < "$CHUNK_FILE")
            echo "   ðŸ“„ $CHUNK_LINES linhas"

            ATTEMPT=0
            CHUNK_SUCCESS=false

            while [ "$CHUNK_SUCCESS" = "false" ]; do
              ATTEMPT=$((ATTEMPT + 1))

              echo "   ðŸ”„ Tentativa #$ATTEMPT"

              API_KEY=$(get_available_key)

              if [ -z "$API_KEY" ]; then
                echo "   âš ï¸ Sem keys disponÃ­veis! Aguardando 5 minutos..."
                sleep 300
                continue
              fi

              KEY_SHORT="${API_KEY:0:8}...${API_KEY: -4}"
              echo "   ðŸ”‘ Key: $KEY_SHORT"

              # Buscar projeto associado a esta key
              KEY_PROJECT=$(get_project_for_key "$API_KEY")
              echo "   ðŸ“‚ Projeto: ${KEY_PROJECT:-desconhecido}"

              # Marcar key como usada COM o projeto
              mark_key_used "$API_KEY" "$CHUNK_NAME" "$KEY_PROJECT"

              # Commit do usage file
              git add "$USAGE_FILE" 2>/dev/null
              git diff --cached --quiet 2>/dev/null || {
                git commit -m "ðŸ”„ Key em uso: $CHUNK_NAME [${KEY_PROJECT:-?}]" --quiet 2>/dev/null
                git push --quiet 2>/dev/null
              }

              # Criar venv isolada
              VENV_DIR="tmp_venvs/venv_${CHUNK_NAME}_${ATTEMPT}"
              echo "   ðŸ“¦ Criando venv..."

              python3 -m venv "$VENV_DIR" 2>/dev/null
              source "$VENV_DIR/bin/activate"
              pip install -q google-genai 2>/dev/null

              SCRIPT_FILE="tmp_venvs/analyze_${CHUNK_NAME}_${ATTEMPT}.py"

              cat > "$SCRIPT_FILE" <<'PYSCRIPT'
          import sys
          import json
          import os

          def main():
              api_key = sys.argv[1]
              chunk_file = sys.argv[2]
              output_file = sys.argv[3]
              prompt_file = sys.argv[4]
              model_name = sys.argv[5]

              with open(prompt_file, 'r', encoding='utf-8') as f:
                  prompt_template = f.read()

              with open(chunk_file, 'r', encoding='utf-8') as f:
                  chunk_content = f.read()

              full_prompt = prompt_template + "\n\n" + chunk_content

              try:
                  from google import genai

                  client = genai.Client(api_key=api_key)

                  response = client.models.generate_content(
                      model=model_name,
                      contents=full_prompt,
                      config={
                          "temperature": 0.3,
                          "max_output_tokens": 65536,
                      }
                  )

                  raw_text = response.text.strip()

                  if raw_text.startswith("```"):
                      lines = raw_text.split("\n")
                      if lines[0].startswith("```"):
                          lines = lines[1:]
                      if lines and lines[-1].strip() == "```":
                          lines = lines[:-1]
                      raw_text = "\n".join(lines).strip()

                  parsed = json.loads(raw_text)

                  if "clips" not in parsed:
                      print("ERROR: JSON nao contem 'clips'", file=sys.stderr)
                      sys.exit(1)

                  if not isinstance(parsed["clips"], list):
                      print("ERROR: 'clips' nao e uma lista", file=sys.stderr)
                      sys.exit(1)

                  with open(output_file, 'w', encoding='utf-8') as f:
                      json.dump(parsed, f, indent=2, ensure_ascii=False)

                  clip_count = len(parsed["clips"])
                  print(f"OK:{clip_count}")

              except json.JSONDecodeError as e:
                  print(f"ERROR_JSON: {e}", file=sys.stderr)
                  debug_file = output_file + ".raw.txt"
                  try:
                      with open(debug_file, 'w', encoding='utf-8') as f:
                          f.write(raw_text if 'raw_text' in dir() else "NO_RESPONSE")
                  except:
                      pass
                  sys.exit(2)

              except Exception as e:
                  print(f"ERROR_API: {str(e)}", file=sys.stderr)
                  sys.exit(3)

          if __name__ == "__main__":
              main()
          PYSCRIPT

              OUTPUT_JSON="$OUTPUT_DIR/${CHUNK_NAME}.json"

              RESULT=$("$VENV_DIR/bin/python3" "$SCRIPT_FILE" \
                "$API_KEY" \
                "$CHUNK_FILE" \
                "$OUTPUT_JSON" \
                "tmp_prompt_template.txt" \
                "$MODEL" \
                2>&1)

              EXIT_CODE=$?

              deactivate 2>/dev/null

              if [ $EXIT_CODE -eq 0 ]; then
                CLIPS_IN_CHUNK=$(echo "$RESULT" | grep -oP 'OK:\K\d+' || echo "0")
                echo "   âœ… Sucesso! $CLIPS_IN_CHUNK clips gerados"
                TOTAL_CLIPS=$((TOTAL_CLIPS + CLIPS_IN_CHUNK))
                SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                CHUNK_SUCCESS=true

                rm -rf "$VENV_DIR" "$SCRIPT_FILE"
              else
                echo "   âŒ Erro (code=$EXIT_CODE): $(echo "$RESULT" | tail -1)"
                echo "   ðŸ”„ Marcando key como expirada e tentando outra..."

                mark_key_expired "$API_KEY" "error_code_${EXIT_CODE}_chunk_${CHUNK_NAME}" "$KEY_PROJECT"

                git add "$USAGE_FILE" 2>/dev/null
                git diff --cached --quiet 2>/dev/null || {
                  git commit -m "âŒ Key expirada: $CHUNK_NAME" --quiet 2>/dev/null
                  git push --quiet 2>/dev/null
                }

                rm -rf "$VENV_DIR" "$SCRIPT_FILE"
                sleep 5
              fi
            done

            echo ""
          done

          ##############################################################
          # JUNTAR TODOS OS JSON
          ##############################################################
          echo ""
          echo "ðŸ”— Juntando todos os resultados..."

          python3 - "$OUTPUT_DIR" <<'PYMERGE'
          import json, os, sys, glob

          output_dir = sys.argv[1]
          all_clips = []

          json_files = sorted(glob.glob(os.path.join(output_dir, "chunk_*.json")))

          for jf in json_files:
              try:
                  with open(jf, 'r', encoding='utf-8') as f:
                      data = json.load(f)
                  clips = data.get('clips', [])
                  all_clips.extend(clips)
                  print(f"  âœ… {os.path.basename(jf)}: {len(clips)} clips")
              except Exception as e:
                  print(f"  âŒ {os.path.basename(jf)}: {e}")

          seen_ids = set()
          unique_clips = []
          for clip in all_clips:
              cid = clip.get('clip_id', '')
              if cid not in seen_ids:
                  seen_ids.add(cid)
                  unique_clips.append(clip)

          def time_to_secs(t):
              try:
                  parts = t.split(':')
                  return int(parts[0])*3600 + int(parts[1])*60 + int(parts[2])
              except:
                  return 0

          unique_clips.sort(key=lambda c: time_to_secs(c.get('start_time', '00:00:00')))

          final = {"clips": unique_clips}

          with open("analise_resultado.json", 'w', encoding='utf-8') as f:
              json.dump(final, f, indent=2, ensure_ascii=False)

          yt = sum(1 for c in unique_clips if c.get('platform') in ('youtube', 'both'))
          tt = sum(1 for c in unique_clips if c.get('platform') in ('tiktok', 'both'))
          total_dur = sum(c.get('duration_seconds', 0) for c in unique_clips)

          print(f"\n{'='*50}")
          print(f"  Total de clips unicos: {len(unique_clips)}")
          print(f"  YouTube/Both: {yt}")
          print(f"  TikTok/Both: {tt}")
          print(f"  Duracao total: {total_dur//3600}h{(total_dur%3600)//60}m")
          print(f"{'='*50}")
          PYMERGE

          ##############################################################
          # GERAR RELATÃ“RIO TXT
          ##############################################################
          python3 - <<'PYREPORT'
          import json

          with open("analise_resultado.json", 'r', encoding='utf-8') as f:
              data = json.load(f)

          clips = data.get('clips', [])

          with open("analise_resultado.txt", 'w', encoding='utf-8') as f:
              f.write("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
              f.write("â•‘     ðŸŽ¬ RESULTADO DA ANÃLISE - CLIPES GERADOS    â•‘\n")
              f.write("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

              yt_clips = [c for c in clips if c.get('platform') in ('youtube', 'both')]
              tt_clips = [c for c in clips if c.get('platform') in ('tiktok', 'both')]

              f.write(f"Total: {len(clips)} clipes\n")
              f.write(f"YouTube: {len(yt_clips)} | TikTok: {len(tt_clips)}\n")
              f.write("=" * 60 + "\n\n")

              if yt_clips:
                  f.write("ðŸŽ¥ CLIPES PARA YOUTUBE\n")
                  f.write("-" * 60 + "\n\n")
                  for i, c in enumerate(yt_clips, 1):
                      f.write(f"  [{i}] {c.get('title', 'Sem titulo')}\n")
                      f.write(f"      â±ï¸  {c.get('start_time')} â†’ {c.get('end_time')} ({c.get('duration_seconds', 0)}s)\n")
                      f.write(f"      ðŸ“‚ {c.get('category', '?')}\n")
                      f.write(f"      ðŸ’¡ {c.get('reason', '')}\n")
                      f.write(f"      ðŸ·ï¸  {', '.join(c.get('tags', []))}\n")
                      f.write(f"      ðŸ’° Monetizavel: {'âœ…' if c.get('monetizable') else 'âŒ'}\n")
                      flags = c.get('safety_flags', [])
                      if flags:
                          f.write(f"      âš ï¸  Flags: {', '.join(flags)}\n")
                      f.write(f"      ðŸ“ {c.get('recommended_description', '')}\n")
                      f.write(f"      ðŸ–¼ï¸  Thumbnail: \"{c.get('thumbnail_text', '')}\" @ {c.get('thumbnail_timestamp', '')}\n")
                      f.write(f"      ðŸ“Ž Segmentos: {c.get('segments_combined', [])}\n")
                      f.write("\n")

              if tt_clips:
                  f.write("\nðŸ“± CLIPES PARA TIKTOK\n")
                  f.write("-" * 60 + "\n\n")
                  for i, c in enumerate(tt_clips, 1):
                      f.write(f"  [{i}] {c.get('title', 'Sem titulo')}\n")
                      f.write(f"      â±ï¸  {c.get('start_time')} â†’ {c.get('end_time')} ({c.get('duration_seconds', 0)}s)\n")
                      f.write(f"      ðŸ“‚ {c.get('category', '?')}\n")
                      f.write(f"      ðŸ’¡ {c.get('reason', '')}\n")
                      f.write(f"      ðŸ·ï¸  {', '.join(c.get('tags', []))}\n")
                      f.write(f"      ðŸ’° Monetizavel: {'âœ…' if c.get('monetizable') else 'âŒ'}\n")
                      f.write(f"      ðŸ“ {c.get('recommended_description', '')}\n")
                      f.write(f"      ðŸ–¼ï¸  Thumbnail: \"{c.get('thumbnail_text', '')}\" @ {c.get('thumbnail_timestamp', '')}\n")
                      f.write("\n")

          print("ðŸ“„ Relatorio TXT gerado")
          PYREPORT

          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘          âœ… ANÃLISE CONCLUÃDA                    â•‘"
          echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
          echo "â•‘  Chunks processados: $SUCCESS_COUNT/$TOTAL_CHUNKS"
          echo "â•‘  Total de clips:     $TOTAL_CLIPS"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

          rm -rf tmp_chunks tmp_venvs tmp_prompt_template.txt

      - name: Commit resultados
        run: |
          git config user.name "bot"
          git config user.email "bot@users.noreply.github.com"
          git add analise_resultado.json analise_resultado.txt key_usage.json
          git diff --cached --quiet && echo "Sem mudanÃ§as" && exit 0
          CLIPS=$(python3 -c "import json; print(len(json.load(open('analise_resultado.json'))['clips']))" 2>/dev/null || echo "0")
          git commit -m "ðŸŽ¬ AnÃ¡lise: $CLIPS clips - $(date -u '+%H:%M UTC')"
          git push

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: analise-resultado
          path: |
            analise_resultado.json
            analise_resultado.txt
          retention-days: 30
